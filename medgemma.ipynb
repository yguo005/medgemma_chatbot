{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L57et_oS8282",
    "outputId": "a7ac4a57-2056-4dfb-9ecb-fc7ab1c6f12d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into 'medgemma_chatbot'...\n",
      "remote: Enumerating objects: 142, done.\u001b[K\n",
      "remote: Counting objects: 100% (142/142), done.\u001b[K\n",
      "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
      "remote: Total 142 (delta 44), reused 138 (delta 40), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (142/142), 22.41 MiB | 12.08 MiB/s, done.\n",
      "Resolving deltas: 100% (44/44), done.\n",
      "/content/medgemma_chatbot\n"
     ]
    }
   ],
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "# --- 1. Define constants and secrets ---\n",
    "GIT_TOKEN = userdata.get('github_token')\n",
    "GITHUB_USER = 'yguo005'\n",
    "GITHUB_REPO = 'medgemma_chatbot'\n",
    "BRANCH_NAME = 'main'\n",
    "\n",
    "# --- 2. ALWAYS start from a clean state in /content ---\n",
    "# Go back to the root content directory to avoid nested paths\n",
    "%cd /content\n",
    "\n",
    "# Remove the repository directory if it already exists to ensure a fresh clone\n",
    "!rm -rf {GITHUB_REPO}\n",
    "\n",
    "# --- 3. clone the branch ---\n",
    "!git clone https://github.com/yguo005/medgemma_chatbot.git\n",
    "\n",
    "# --- 4. Change directory into the newly cloned project ---\n",
    "%cd {GITHUB_REPO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "la96xdK8toZL"
   },
   "outputs": [],
   "source": [
    "#------------------DON'T RUN-------------------------------\n",
    "#----------------------------------------------------------\n",
    "#----------------------------------------------------------\n",
    "\n",
    "# ---Install System and Python Dependencies ---\n",
    "# First, install system-level build tools for FAISS\n",
    "print(\"Installing system dependencies for FAISS...\")\n",
    "!pip install --upgrade -q pip\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq libomp-dev cmake\n",
    "\n",
    "# --- 2. Install faiss-gpu by itself ---\n",
    "# install it separately to isolate any issues.\n",
    "\n",
    "print(\"Installing faiss-cpu...\")\n",
    "!pip install -q faiss-cpu==1.8.0\n",
    "\n",
    "# --- 3. Install the rest of the Python packages ---\n",
    "print(\"\\nInstalling remaining Python packages...\")\n",
    "!pip install -q \\\n",
    "    \"torch==2.2.2\" \\\n",
    "    \"transformers>=4.42.4\" \\\n",
    "    \"accelerate==0.29.3\" \\\n",
    "    \"bitsandbytes==0.43.1\" \\\n",
    "    \"langchain==0.1.16\" \\\n",
    "    \"langchain-community==0.0.38\" \\\n",
    "    \"langchain-openai==0.1.3\" \\\n",
    "    \"fastapi==0.110.0\" \\\n",
    "    \"uvicorn==0.29.0\" \\\n",
    "    \"python-multipart==0.0.9\" \\\n",
    "    \"pypdf\" \\\n",
    "    \"python-dotenv\" \\\n",
    "    \"google-cloud-aiplatform==1.47.0\" \\\n",
    "    \"pyngrok==7.1.6\" \\\n",
    "    \"pydantic==1.10.13\"\n",
    "\n",
    "print(\"\\n All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xlApthY1XE7L",
    "outputId": "a535db53-919f-4abf-bc22-9fa8f5d4e6ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing all packages with latest compatible versions...\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.12/dist-packages (2.11.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0) (0.4.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.29)\n",
      "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (0.3.32)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.10)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.20)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (23.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: pip>=25.2 in /usr/local/lib/python3.12/dist-packages (from langchain-text-splitters<1.0.0,>=0.3.9->langchain) (25.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.101.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~orch (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m \n",
      "Installation completed!\n"
     ]
    }
   ],
   "source": [
    "# ---Install System and Python Dependencies ---\n",
    "print(\"Installing all packages with latest compatible versions...\")\n",
    "!pip install -q \\\n",
    "    torch \\\n",
    "    \"transformers>=4.42.4\" \\\n",
    "    accelerate \\\n",
    "    bitsandbytes \\\n",
    "    langchain \\\n",
    "    langchain-community \\\n",
    "    langchain-openai \\\n",
    "    faiss-cpu \\\n",
    "    fastapi \\\n",
    "    uvicorn \\\n",
    "    python-multipart \\\n",
    "    pypdf \\\n",
    "    python-dotenv \\\n",
    "    google-cloud-aiplatform \\\n",
    "    pyngrok \\\n",
    "    pydantic \\\n",
    "    starlette\n",
    "!pip install --upgrade \"pydantic>=2.0.0\"\n",
    "!pip install --upgrade langchain langchain-community langchain-openai\n",
    "!pip install --upgrade torch torchvision torchaudio\n",
    "\n",
    "print(\" \\nInstallation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lfh4Z0vB6AIL"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth, userdata\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Authenticate for Google Cloud services\n",
    "auth.authenticate_user()\n",
    "\n",
    "# Set environment variables from Colab Secrets\n",
    "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "os.environ['NGROK_AUTHTOKEN'] = userdata.get('NGROK_AUTHTOKEN')\n",
    "\n",
    "# Manually set other env vars for the demo\n",
    "os.environ['DEPLOYMENT_MODE'] = 'development'\n",
    "os.environ['USE_MEDGEMMA_GARDEN'] = 'false'\n",
    "\n",
    "#  Log in to Hugging Face\n",
    "# This uses the HF_TOKEN secret to authenticate session\n",
    "HF_TOKEN = userdata.get('HF_TOKEN')\n",
    "login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7tU4IAm27csa",
    "outputId": "48f5b72a-e630-4b66-c1b1-cc4f02b93382"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Configuration Status:\n",
      "   Mode: development\n",
      "   MedGemma: Local HF\n",
      "   Valid: True\n",
      "\n",
      " Creating FAISS Vector Store for AI Health Consultant\n",
      "============================================================\n",
      " Current script: /content/medgemma_chatbot/src/services/ai/rag/create_memory_for_llm.py\n",
      " Project root: /content/medgemma_chatbot\n",
      " Data path: /content/medgemma_chatbot/data/document\n",
      " FAISS path: /content/medgemma_chatbot/data/vectorstore/db_faiss\n",
      " Project root exists: True\n",
      " Data directory exists: True\n",
      "\n",
      " Loaded 759 documents from 1 PDF file(s)\n",
      " Created 7080 text chunks.\n",
      " OpenAI Embedding Model Loaded (Vector Dimension: 1536)\n",
      " FAISS vector store already exists. Overwriting...\n",
      " FAISS vector store created and saved to: /content/medgemma_chatbot/data/vectorstore/db_faiss\n"
     ]
    }
   ],
   "source": [
    "# Build the Knowledge Base\n",
    "!python /content/medgemma_chatbot/src/services/ai/rag/create_memory_for_llm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 805,
     "referenced_widgets": [
      "67a7e8c015f84d0892ee4fe374d903a2",
      "2fd41b3d39df4dd6ac179df4e18f0ae5",
      "a1988c2aee7244da9bfc4a5bc29bf630",
      "f2da64126c6142119450acc3e69c5a0c",
      "6030a9fa7d5f417b9dfe239abd1810fe",
      "3844d79d609f424a931dad8b14f4f9ed",
      "947fa1aab68a411392614ee099736959",
      "ab2db972ef9e48e08e07df697faba863",
      "9e116816749446a2b78fa459de2dfbe8",
      "dbd392591a824224922db53c4ab7095f",
      "5f5c4d2c5c8f48509e85ec4f7fbe34ee",
      "a4a2e3fdc0ab4aadbe795aab8fe65c66",
      "e34a801175e649ad95fc5f194d94a42d",
      "47c9336a07464832a37807829662c086",
      "9bfcdef80b754b21bc36677708c076db",
      "f4250548431f43b98bd3e3fa5b5e8e05",
      "a6436497902a4aeeadd9bc949376fc8c",
      "a54586aaaab64d5695c60c7a6a2ecbfc",
      "31bf3a6d57cc4408a338e3d1c3095de2",
      "e10753f9bc23493a9e88c4fb27855ca4",
      "33e758cc8bcf439885ae86f62f5de357",
      "691b25932cbc43e9b83adc878ad6ba7d",
      "07dcea4035e0479b9edee2a4fae0fb16",
      "1a77e92e23c746ed8f6db8621824200d",
      "e118f7b2341044d7b4e7f01175d82b51",
      "a76177201a3d4800a0dba3eb96002f95",
      "1b693c90a6414846ac32d755a7d5340a",
      "0f8944cc2024492a8061bcd362be4aa7",
      "00391affbde34e77b271d18083501b74",
      "59e981e24e2d45fc9dc21beac1f58ddb",
      "54cd0699acc84d2fbe309c231d37f60b",
      "44ebaf24a5d54f98beaba6a6e441fb3f",
      "3575dffbfbe6486481ae08493960753d",
      "da04e707fcd3452a8d58e0ec6c7aa030",
      "3f75b78b59354e568af4467f14c50710",
      "872ae8b286bf401f93cc17342a31ecef",
      "11a97f9e988a44269831f57dbab9f442",
      "ee5b5b77a0154d9e87e34674a9646793",
      "843b68ec67ed40e58afebbd7ab7de8b0",
      "732a556259504be1a4c4ed147c2cc7ad",
      "c81336fe9b484efb90f8ea29cfda1e26",
      "a009d15245b54eee9228f3f300a21489",
      "10e37d7e0ae94dcca6ee2bb40560ed68",
      "2d940ec0e9d14397b1e27f98c7796bb2",
      "56d7b72c6ec44e5ba0e14ff0b28d7cdf",
      "86b4b1600c304a0caa7ca9766ece1a62",
      "7977c17ffb234b1c9aea2956825311a4",
      "66b3edc28448455387fbe5ed4105d51e",
      "deafe0a536ff48a8bf78599bc95beb6a",
      "c030d490a65646e3a4da1095a4e13799",
      "0f8424217114479e87bf3ca2772723d6",
      "62a739a36a8246fa9bcd3cf788027d49",
      "a147c15d374d499091bdf320673c6493",
      "54080ad0350e4ac29a2dbe03c04ef495",
      "5bedbc15d66841369ccfda4cba49f78d",
      "e6fffca3ae904a40bfe94e0da68b1cff",
      "11d4245dd39348b0af8f0312e0c062d4",
      "617f4478b81c44e2b9b2b77eaa2d0332",
      "91b6a91a180649bf98378c89aa35518f",
      "2f12aa6400f748179cdd30ef96e726a5",
      "c0e5a3a4e3fc4b8ba5283d41e99b1666",
      "6e809e7c3d1f4cf3a3abc86839d6ed91",
      "a0edba34a6c74562bc0e1aeebca7de42",
      "a8aad3c543d54bb199687d43c9e73148",
      "f750aa16efea45d0946f7587374a7e5a",
      "4e9971d949a84b8c99f41457024ad918",
      "f82e25a25d5a436bb234bf02c0140731",
      "81e6431d1ada48b9b6844697b6469102",
      "e0d5088b178c4e11988c19fa518d5fe4",
      "0e6383b3f3c447648468f07db8eb24d7",
      "f4f8664326e34fa4814df4b38d9a5e38",
      "94f73066781345878ae95109384a3278",
      "deae0f2d9cea4331b4b61863803165d1",
      "88141b1dba5044aa90e07a3129045d83",
      "ebed299f44454f99ba9bde78ac8512d4",
      "3167dd5732f3423589786d7271b9c377",
      "5c999fd4f59f49658a503efe0406d9df"
     ]
    },
    "id": "j2z19R26D2MA",
    "outputId": "1ac23ed0-e1c3-4322-94a8-558e5a5498af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting FastAPI server...\n",
      " Working directory: /content/medgemma_chatbot\n",
      " Opening ngrok tunnel...\n",
      " FastAPI server is live at: NgrokTunnel: \"https://b5c26f371aae.ngrok-free.app\" -> \"http://localhost:8000\"\n",
      " Mobile interface: NgrokTunnel: \"https://b5c26f371aae.ngrok-free.app\" -> \"http://localhost:8000\"/mobile.html\n",
      " Desktop interface: NgrokTunnel: \"https://b5c26f371aae.ngrok-free.app\" -> \"http://localhost:8000\"/\n",
      " API docs: NgrokTunnel: \"https://b5c26f371aae.ngrok-free.app\" -> \"http://localhost:8000\"/docs\n",
      "\n",
      " To stop the server, interrupt this cell (Runtime > Interrupt execution)\n",
      "\n",
      " Configuration Status:\n",
      "   Mode: development\n",
      "   MedGemma: Local HF\n",
      "   Valid: True\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pyngrok.process.ngrok:t=2025-08-29T20:05:11+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a7e8c015f84d0892ee4fe374d903a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a2e3fdc0ab4aadbe795aab8fe65c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dcea4035e0479b9edee2a4fae0fb16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da04e707fcd3452a8d58e0ec6c7aa030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d7b72c6ec44e5ba0e14ff0b28d7cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fffca3ae904a40bfe94e0da68b1cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82e25a25d5a436bb234bf02c0140731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "WARNING:bitsandbytes.cextension:Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "WARNING:bitsandbytes.cextension:The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "ERROR:src.services.ai.medgemma.medgemma_service: Failed to load MedGemma model: Could not import module 'validate_bnb_backend_availability'. Are this object's requirements defined correctly?\n",
      "INFO:     Started server process [57486]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     73.92.81.141:0 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     73.92.81.141:0 - \"GET /static/css/style.css HTTP/1.1\" 200 OK\n",
      "INFO:     73.92.81.141:0 - \"GET /static/js/main.js HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [57486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaned up ngrok tunnel\n"
     ]
    }
   ],
   "source": [
    "# Run the FastAPI Server with Enhanced Debugging\n",
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import logging\n",
    "from pyngrok import ngrok, conf\n",
    "\n",
    "# Set up detailed logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('src'))\n",
    "\n",
    "# Validate environment variables\n",
    "NGROK_TOKEN = os.environ.get(\"NGROK_AUTHTOKEN\")\n",
    "OPENAI_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not NGROK_TOKEN:\n",
    "    print(\"❌ ERROR: NGROK_AUTHTOKEN not set!\")\n",
    "    print(\"Set it with: os.environ['NGROK_AUTHTOKEN'] = 'your-token-here'\")\n",
    "    sys.exit(1)\n",
    "\n",
    "if not OPENAI_KEY:\n",
    "    print(\"❌ ERROR: OPENAI_API_KEY not set!\")\n",
    "    print(\"Set it with: os.environ['OPENAI_API_KEY'] = 'your-key-here'\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Set the ngrok auth token\n",
    "conf.get_default().auth_token = NGROK_TOKEN\n",
    "\n",
    "async def run_fastapi():\n",
    "    try:\n",
    "        # Use nest_asyncio to allow uvicorn to run in a notebook\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "\n",
    "        # Import uvicorn\n",
    "        import uvicorn\n",
    "\n",
    "        print(\"🚀 Starting FastAPI server with enhanced debugging...\")\n",
    "        print(f\"📁 Working directory: {os.getcwd()}\")\n",
    "\n",
    "        # Check if main.py exists\n",
    "        if not os.path.exists(\"main.py\"):\n",
    "            print(\"❌ ERROR: main.py not found in current directory!\")\n",
    "            print(\"Make sure you're in the correct directory with your FastAPI app.\")\n",
    "            return\n",
    "\n",
    "        # Test import of main.py to catch any initialization errors\n",
    "        try:\n",
    "            import main\n",
    "            print(\"✅ main.py imported successfully\")\n",
    "            \n",
    "            # Check if the app is properly initialized\n",
    "            if hasattr(main, 'app'):\n",
    "                print(\"✅ FastAPI app found\")\n",
    "            else:\n",
    "                print(\"⚠️  Warning: No 'app' attribute found in main.py\")\n",
    "                \n",
    "            # Check service status\n",
    "            if hasattr(main, 'conversation_manager') and main.conversation_manager:\n",
    "                print(\"✅ ConversationManager initialized\")\n",
    "            else:\n",
    "                print(\"⚠️  Warning: ConversationManager not properly initialized\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error importing main.py: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return\n",
    "\n",
    "        # Configure uvicorn server with debug logging\n",
    "        config = uvicorn.Config(\n",
    "            \"main:app\",\n",
    "            host=\"0.0.0.0\",\n",
    "            port=8000,\n",
    "            log_level=\"debug\",  # Changed to debug for more detailed logs\n",
    "            reload=False,  # Disable reload in Colab\n",
    "            access_log=True  # Enable access logs\n",
    "        )\n",
    "        server = uvicorn.Server(config)\n",
    "\n",
    "        # Open a tunnel to the uvicorn server\n",
    "        print(\"🌐 Opening ngrok tunnel...\")\n",
    "        public_url = ngrok.connect(8000)\n",
    "        print(f\"✅ FastAPI server is live at: {public_url}\")\n",
    "        print(f\"📱 Mobile interface: {public_url}/mobile\")\n",
    "        print(f\"🖥️  Desktop interface: {public_url}/\")\n",
    "        print(f\"📚 API docs: {public_url}/docs\")\n",
    "        print(f\"🔍 Health check: {public_url}/health\")\n",
    "        print(\"\\n⚠️  To stop the server, interrupt this cell (Runtime > Interrupt execution)\")\n",
    "        print(\"\\n🐛 Debug Tips:\")\n",
    "        print(\"   - Check the logs below for any errors\")\n",
    "        print(\"   - Try the health check endpoint first\")\n",
    "        print(\"   - If you see errors, check the debug cell output above\")\n",
    "\n",
    "        # Run the server\n",
    "        await server.serve()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error starting server: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        # Clean up ngrok tunnels\n",
    "        try:\n",
    "            ngrok.disconnect(8000)\n",
    "            print(\"🧹 Cleaned up ngrok tunnel\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Run the server asynchronously\n",
    "await run_fastapi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Test the conversation flow before starting the server\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('src'))\n",
    "\n",
    "try:\n",
    "    # Test imports\n",
    "    from src.services.ai.rag.chatbot import Chatbot\n",
    "    from src.services.conversation.manager import ConversationManager\n",
    "    from src.services.ai.ai_service_manager import create_ai_service_manager\n",
    "    from src.services.safety.safety_guardrails import MedicalSafetyGuardrails\n",
    "    \n",
    "    print(\" All imports successful\")\n",
    "    \n",
    "    # Test service initialization\n",
    "    OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    \n",
    "    # Initialize services\n",
    "    chatbot = Chatbot(\n",
    "        openai_api_key=OPENAI_API_KEY,\n",
    "        use_medgemma_garden=False,\n",
    "        gcp_project_id=None,\n",
    "        endpoint_id=None\n",
    "    )\n",
    "    \n",
    "    ai_service_manager = create_ai_service_manager(\"hybrid\")\n",
    "    \n",
    "    conversation_manager = ConversationManager(\n",
    "        ai_service=ai_service_manager,\n",
    "        rag_service=chatbot\n",
    "    )\n",
    "    \n",
    "    print(\" Services initialized successfully\")\n",
    "    \n",
    "    # Test the conversation flow\n",
    "    import asyncio\n",
    "    \n",
    "    async def test_conversation():\n",
    "        try:\n",
    "            response = await conversation_manager.process_message(\"test_session\", \"i have headache\", False)\n",
    "            print(\" Conversation test successful:\")\n",
    "            print(f\"   Response type: {response.get('response_type')}\")\n",
    "            print(f\"   Response: {response.get('response_text', response.get('response', 'No response'))[:100]}...\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(\" Conversation test failed:\")\n",
    "            print(f\"   Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "    \n",
    "    # Run the test\n",
    "    success = await test_conversation()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n All tests passed! The server should work correctly.\")\n",
    "    else:\n",
    "        print(\"\\n  There are issues that need to be fixed before starting the server.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\" Setup failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MedGemma Service Directly\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('src'))\n",
    "\n",
    "try:\n",
    "    from src.services.ai.medgemma.medgemma_service import MedGemmaService\n",
    "    \n",
    "    print(\" Testing MedGemma service initialization...\")\n",
    "    \n",
    "    # Test with basic settings (non-multimodal, no quantization for Colab)\n",
    "    medgemma = MedGemmaService(\n",
    "        model_name=\"google/medgemma-4b-it\",\n",
    "        device=\"auto\",\n",
    "        use_quantization=False,  # Disable for Colab stability\n",
    "        multimodal=False  # Start with text-only\n",
    "    )\n",
    "    \n",
    "    print(\" MedGemma service created\")\n",
    "    \n",
    "    # Check model info\n",
    "    info = medgemma.get_model_info()\n",
    "    print(f\" Model Status:\")\n",
    "    print(f\"   - Model loaded: {info['model_loaded']}\")\n",
    "    print(f\"   - Tokenizer loaded: {info['tokenizer_loaded']}\")\n",
    "    print(f\"   - Pipeline ready: {info['pipeline_ready']}\")\n",
    "    print(f\"   - Device: {info['device']}\")\n",
    "    print(f\"   - CUDA available: {info['cuda_available']}\")\n",
    "    \n",
    "    if info['model_loaded'] and info['pipeline_ready']:\n",
    "        print(\"\\n Testing medical response generation...\")\n",
    "        \n",
    "        # Test simple medical query\n",
    "        import asyncio\n",
    "        async def test_medgemma():\n",
    "            try:\n",
    "                response = await medgemma.generate_medical_response(\n",
    "                    query=\"I have a headache\",\n",
    "                    max_length=200\n",
    "                )\n",
    "                \n",
    "                if response['success']:\n",
    "                    print(\" MedGemma response test successful!\")\n",
    "                    print(f\"   Response: {response['response'][:150]}...\")\n",
    "                    return True\n",
    "                else:\n",
    "                    print(f\" MedGemma response failed: {response['error']}\")\n",
    "                    return False\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\" MedGemma test error: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                return False\n",
    "        \n",
    "        success = await test_medgemma()\n",
    "        \n",
    "        if success:\n",
    "            print(\"\\n MedGemma service is working correctly!\")\n",
    "        else:\n",
    "            print(\"\\n  MedGemma service has issues - this may cause conversation errors\")\n",
    "    else:\n",
    "        print(\"\\n MedGemma service is not properly initialized\")\n",
    "        print(\"   This will cause the conversation flow to fail\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\" MedGemma service test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 COMPREHENSIVE FIX - Run this cell to resolve all remaining errors\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "sys.path.insert(0, os.path.abspath('src'))\n",
    "\n",
    "print(\"🔧 Applying comprehensive fixes for all remaining errors...\")\n",
    "print(\"   Fixed: Accelerate device management conflict\")\n",
    "print(\"   Fixed: AI Service Manager parameter forwarding\")\n",
    "print(\"   Fixed: MedGemma processor eos_token_id handling\")\n",
    "\n",
    "# Reload modules to ensure we get the latest fixes\n",
    "modules_to_reload = [\n",
    "    'src.services.ai.medgemma.medgemma_service',\n",
    "    'src.services.conversation.manager', \n",
    "    'src.services.ai.ai_service_manager',\n",
    "    'src.services.ai.rag.chatbot'\n",
    "]\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        importlib.reload(sys.modules[module_name])\n",
    "        print(f\"   ✅ Reloaded {module_name}\")\n",
    "\n",
    "print(\"\\n1️⃣ Testing MedGemma Service with Accelerate compatibility...\")\n",
    "try:\n",
    "    from src.services.ai.medgemma.medgemma_service import MedGemmaService\n",
    "    \n",
    "    # Test with safer settings for Colab - this should now work without Accelerate conflicts\n",
    "    medgemma = MedGemmaService(\n",
    "        model_name=\"google/medgemma-4b-it\",\n",
    "        device=\"auto\",\n",
    "        use_quantization=False,  # Disable quantization - should avoid Accelerate device_map\n",
    "        multimodal=False  # Start with text-only\n",
    "    )\n",
    "    \n",
    "    info = medgemma.get_model_info()\n",
    "    print(f\"   Model loaded: {info['model_loaded']}\")\n",
    "    print(f\"   Pipeline ready: {info['pipeline_ready']}\")\n",
    "    print(f\"   Device: {info['device']}\")\n",
    "    \n",
    "    if info['model_loaded'] and info['pipeline_ready']:\n",
    "        # Test medical response generation\n",
    "        async def test_medgemma_direct():\n",
    "            try:\n",
    "                response = await medgemma.generate_medical_response(\n",
    "                    query=\"I have a headache\", \n",
    "                    max_length=100,  # Shorter to avoid memory issues\n",
    "                    temperature=0.1  # Lower temperature for more stable output\n",
    "                )\n",
    "                if response['success']:\n",
    "                    print(f\"   ✅ MedGemma direct test: {response['response'][:80]}...\")\n",
    "                    return True\n",
    "                else:\n",
    "                    print(f\"   ❌ MedGemma direct test failed: {response.get('error')}\")\n",
    "                    return False\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ MedGemma direct test error: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                return False\n",
    "        \n",
    "        medgemma_success = await test_medgemma_direct()\n",
    "    else:\n",
    "        print(\"   ❌ MedGemma service not properly initialized\")\n",
    "        print(f\"   Debug info: {info}\")\n",
    "        medgemma_success = False\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   ❌ MedGemma service test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    medgemma_success = False\n",
    "\n",
    "print(\"\\n2️⃣ Testing AI Service Manager with robust parameter handling...\")\n",
    "try:\n",
    "    from src.services.ai.ai_service_manager import create_ai_service_manager\n",
    "    \n",
    "    ai_service_manager = create_ai_service_manager(\"hybrid\")\n",
    "    \n",
    "    # Test with various parameter combinations\n",
    "    async def test_ai_service_robust():\n",
    "        test_cases = [\n",
    "            {\"query\": \"test\", \"context\": \"\"},  # Basic\n",
    "            {\"query\": \"test\", \"context\": \"\", \"max_length\": 100},  # With max_length\n",
    "            {\"query\": \"test\", \"context\": \"\", \"max_length\": 100, \"temperature\": 0.3},  # Full params\n",
    "        ]\n",
    "        \n",
    "        for i, params in enumerate(test_cases):\n",
    "            try:\n",
    "                response = await ai_service_manager.generate_medical_response(**params)\n",
    "                print(f\"   ✅ Test case {i+1}: Parameters accepted\")\n",
    "            except TypeError as e:\n",
    "                if \"unexpected keyword argument\" in str(e):\n",
    "                    print(f\"   ❌ Test case {i+1}: Parameter error - {e}\")\n",
    "                    return False\n",
    "                else:\n",
    "                    print(f\"   ✅ Test case {i+1}: Parameters accepted (other error: {type(e).__name__})\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ✅ Test case {i+1}: Parameters accepted (runtime error: {type(e).__name__})\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    ai_service_success = await test_ai_service_robust()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   ❌ AI Service Manager test failed: {e}\")\n",
    "    ai_service_success = False\n",
    "\n",
    "print(\"\\n3️⃣ Testing conversation flow with error isolation...\")\n",
    "try:\n",
    "    from src.services.ai.rag.chatbot import Chatbot\n",
    "    from src.services.conversation.manager import ConversationManager\n",
    "    \n",
    "    OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    \n",
    "    # Initialize services with error handling\n",
    "    try:\n",
    "        chatbot = Chatbot(\n",
    "            openai_api_key=OPENAI_API_KEY,\n",
    "            use_medgemma_garden=False,\n",
    "            gcp_project_id=None,\n",
    "            endpoint_id=None\n",
    "        )\n",
    "        print(\"   ✅ Chatbot initialized\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️  Chatbot initialization warning: {e}\")\n",
    "        chatbot = None\n",
    "    \n",
    "    try:\n",
    "        ai_service_manager = create_ai_service_manager(\"hybrid\")\n",
    "        print(\"   ✅ AI Service Manager initialized\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ AI Service Manager failed: {e}\")\n",
    "        ai_service_manager = None\n",
    "    \n",
    "    if ai_service_manager:\n",
    "        conversation_manager = ConversationManager(\n",
    "            ai_service=ai_service_manager,\n",
    "            rag_service=chatbot\n",
    "        )\n",
    "        print(\"   ✅ Conversation Manager initialized\")\n",
    "        \n",
    "        # Test with comprehensive error handling\n",
    "        async def test_conversation_robust():\n",
    "            try:\n",
    "                print(\"   🧪 Testing conversation with 'i have headache'...\")\n",
    "                response = await conversation_manager.process_message(\n",
    "                    \"test_session_robust\", \n",
    "                    \"i have headache\", \n",
    "                    False\n",
    "                )\n",
    "                \n",
    "                response_type = response.get('response_type', 'unknown')\n",
    "                response_text = response.get('response_text', response.get('response', 'No response'))\n",
    "                \n",
    "                print(f\"   ✅ Conversation successful!\")\n",
    "                print(f\"       Response type: {response_type}\")\n",
    "                print(f\"       Response: {str(response_text)[:100]}...\")\n",
    "                \n",
    "                return True\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Conversation test failed: {e}\")\n",
    "                import traceback\n",
    "                print(\"   📋 Full traceback:\")\n",
    "                traceback.print_exc()\n",
    "                return False\n",
    "        \n",
    "        conversation_success = await test_conversation_robust()\n",
    "    else:\n",
    "        print(\"   ❌ Cannot test conversation without AI Service Manager\")\n",
    "        conversation_success = False\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   ❌ Conversation flow test failed: {e}\")\n",
    "    conversation_success = False\n",
    "\n",
    "print(\"\\n🎯 TEST RESULTS SUMMARY:\")\n",
    "print(f\"   MedGemma Service: {'✅ PASS' if medgemma_success else '❌ FAIL'}\")\n",
    "print(f\"   AI Service Manager: {'✅ PASS' if ai_service_success else '❌ FAIL'}\")  \n",
    "print(f\"   Conversation Flow: {'✅ PASS' if conversation_success else '❌ FAIL'}\")\n",
    "\n",
    "if all([medgemma_success, ai_service_success, conversation_success]):\n",
    "    print(\"\\n🎉 ALL TESTS PASSED! The system should work correctly now.\")\n",
    "    print(\"   ✅ Accelerate device management conflict resolved\")\n",
    "    print(\"   ✅ AI Service parameter forwarding working\")\n",
    "    print(\"   ✅ Conversation flow fully functional\")\n",
    "    print(\"\\n   You can now run the FastAPI server and test with 'i have headache'\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Some tests failed. Issues may persist during server operation.\")\n",
    "    print(\"   Check the detailed error messages above for debugging.\")\n",
    "\n",
    "print(\"\\n💡 RECOMMENDED NEXT STEPS:\")\n",
    "print(\"   1. If all tests passed: Run the FastAPI server (cell 6)\")\n",
    "print(\"   2. If MedGemma failed: Check GPU memory and try restarting runtime\")\n",
    "print(\"   3. If conversation failed: Check OPENAI_API_KEY is set correctly\")\n",
    "print(\"   4. Test the web interface with: 'i have headache'\")\n",
    "\n",
    "print(\"\\n✨ Key fixes applied:\")\n",
    "print(\"   • Removed device_map='auto' for non-quantized models\")\n",
    "print(\"   • Added Accelerate compatibility detection for pipeline creation\")\n",
    "print(\"   • Enhanced error handling and parameter forwarding\")\n",
    "print(\"   • Improved processor/tokenizer eos_token_id handling\")\n",
    "\n",
    "print(\"\\n✅ Comprehensive testing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧪 Quick Test: Accelerate Device Management Fix\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('src'))\n",
    "\n",
    "print(\"🧪 Testing Accelerate device management fix...\")\n",
    "\n",
    "try:\n",
    "    # Force reload the fixed module\n",
    "    if 'src.services.ai.medgemma.medgemma_service' in sys.modules:\n",
    "        import importlib\n",
    "        importlib.reload(sys.modules['src.services.ai.medgemma.medgemma_service'])\n",
    "    \n",
    "    from src.services.ai.medgemma.medgemma_service import MedGemmaService\n",
    "    \n",
    "    print(\"   Creating MedGemma service (no quantization, should avoid Accelerate conflicts)...\")\n",
    "    \n",
    "    # This should work without the Accelerate device error\n",
    "    medgemma = MedGemmaService(\n",
    "        model_name=\"google/medgemma-4b-it\",\n",
    "        device=\"auto\", \n",
    "        use_quantization=False,  # This should NOT trigger device_map=\"auto\"\n",
    "        multimodal=False\n",
    "    )\n",
    "    \n",
    "    info = medgemma.get_model_info()\n",
    "    \n",
    "    print(f\"   ✅ Service created successfully!\")\n",
    "    print(f\"   Model loaded: {info['model_loaded']}\")\n",
    "    print(f\"   Pipeline ready: {info['pipeline_ready']}\")\n",
    "    print(f\"   Device: {info['device']}\")\n",
    "    \n",
    "    if info['model_loaded'] and info['pipeline_ready']:\n",
    "        print(\"   🎉 SUCCESS: Accelerate device management fix working!\")\n",
    "        print(\"   The 'cannot be moved to a specific device' error should be resolved.\")\n",
    "    else:\n",
    "        print(\"   ⚠️  Model loaded but pipeline not ready - check for other issues\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   ❌ Test failed: {e}\")\n",
    "    if \"cannot be moved to a specific device\" in str(e):\n",
    "        print(\"   🔧 The Accelerate fix needs further adjustment\")\n",
    "    else:\n",
    "        print(\"   🔍 Different error - check logs above\")\n",
    "    \n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n💡 If this test passes, run the comprehensive test (cell 9) next!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 MEMORY MANAGEMENT FIX - CUDA Out of Memory Resolution\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "sys.path.insert(0, os.path.abspath('src'))\n",
    "\n",
    "print(\"🔧 Resolving CUDA out of memory issues...\")\n",
    "\n",
    "# Step 1: Clear any existing GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    # Check initial memory state\n",
    "    gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    gpu_memory_allocated = torch.cuda.memory_allocated(0) / (1024**3)\n",
    "    gpu_memory_free = gpu_memory_total - gpu_memory_allocated\n",
    "    \n",
    "    print(f\"📊 GPU Memory Status:\")\n",
    "    print(f\"   Total: {gpu_memory_total:.2f} GB\")\n",
    "    print(f\"   Allocated: {gpu_memory_allocated:.2f} GB\")\n",
    "    print(f\"   Free: {gpu_memory_free:.2f} GB\")\n",
    "    \n",
    "    if gpu_memory_free < 3.0:\n",
    "        print(f\"⚠️  Low GPU memory detected ({gpu_memory_free:.2f} GB free)\")\n",
    "        print(\"   Automatic memory management will be applied\")\n",
    "    else:\n",
    "        print(f\"✅ Sufficient GPU memory available ({gpu_memory_free:.2f} GB free)\")\n",
    "else:\n",
    "    print(\"📊 CUDA not available - will use CPU mode\")\n",
    "\n",
    "print(\"\\n🧪 Testing MedGemma with automatic memory management...\")\n",
    "\n",
    "try:\n",
    "    # Force reload the fixed module\n",
    "    if 'src.services.ai.medgemma.medgemma_service' in sys.modules:\n",
    "        import importlib\n",
    "        importlib.reload(sys.modules['src.services.ai.medgemma.medgemma_service'])\n",
    "        print(\"   ✅ Module reloaded with memory management fixes\")\n",
    "    \n",
    "    from src.services.ai.medgemma.medgemma_service import MedGemmaService\n",
    "    \n",
    "    print(\"   🚀 Creating MedGemma service with smart memory management...\")\n",
    "    \n",
    "    # The service will now automatically:\n",
    "    # 1. Check available GPU memory\n",
    "    # 2. Enable quantization if memory is low\n",
    "    # 3. Fall back to CPU if needed\n",
    "    # 4. Handle CUDA OOM errors gracefully\n",
    "    \n",
    "    medgemma = MedGemmaService(\n",
    "        model_name=\"google/medgemma-4b-it\",\n",
    "        device=\"auto\",  # Will auto-detect best device\n",
    "        use_quantization=False,  # Will auto-enable if needed\n",
    "        multimodal=False\n",
    "    )\n",
    "    \n",
    "    info = medgemma.get_model_info()\n",
    "    \n",
    "    print(f\"\\n📋 Results:\")\n",
    "    print(f\"   ✅ Service created successfully!\")\n",
    "    print(f\"   Model loaded: {info['model_loaded']}\")\n",
    "    print(f\"   Pipeline ready: {info['pipeline_ready']}\")\n",
    "    print(f\"   Final device: {info['device']}\")\n",
    "    print(f\"   CUDA available: {info['cuda_available']}\")\n",
    "    \n",
    "    # Check final memory usage\n",
    "    if torch.cuda.is_available():\n",
    "        final_allocated = torch.cuda.memory_allocated(0) / (1024**3)\n",
    "        final_free = gpu_memory_total - final_allocated\n",
    "        print(f\"   GPU memory after loading: {final_allocated:.2f} GB allocated, {final_free:.2f} GB free\")\n",
    "    \n",
    "    if info['model_loaded'] and info['pipeline_ready']:\n",
    "        print(\"\\n🎉 SUCCESS: Memory management fix working!\")\n",
    "        print(\"   CUDA out of memory error resolved\")\n",
    "        \n",
    "        # Quick functionality test\n",
    "        print(\"\\n🧪 Testing model functionality...\")\n",
    "        async def test_model_functionality():\n",
    "            try:\n",
    "                response = await medgemma.generate_medical_response(\n",
    "                    query=\"test medical query\",\n",
    "                    max_length=50,  # Short response to minimize memory usage\n",
    "                    temperature=0.1\n",
    "                )\n",
    "                if response['success']:\n",
    "                    print(\"   ✅ Model functionality test passed\")\n",
    "                    print(f\"   Sample response: {response['response'][:100]}...\")\n",
    "                    return True\n",
    "                else:\n",
    "                    print(f\"   ⚠️  Model response failed: {response.get('error')}\")\n",
    "                    return False\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Functionality test error: {e}\")\n",
    "                return False\n",
    "        \n",
    "        functionality_success = await test_model_functionality()\n",
    "        \n",
    "        if functionality_success:\n",
    "            print(\"\\n🎯 COMPLETE SUCCESS: Model loaded and functional!\")\n",
    "        else:\n",
    "            print(\"\\n🔄 Model loaded but may need further optimization\")\n",
    "            \n",
    "    else:\n",
    "        print(\"\\n❌ Model loading still failed - may need alternative approach\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Memory management test failed: {e}\")\n",
    "    \n",
    "    # Provide specific guidance based on error type\n",
    "    error_str = str(e)\n",
    "    if \"CUDA out of memory\" in error_str:\n",
    "        print(\"\\n🔧 CUDA memory issue persists. Recommendations:\")\n",
    "        print(\"   1. Restart the runtime to clear all GPU memory\")\n",
    "        print(\"   2. Use CPU-only mode: device='cpu'\")\n",
    "        print(\"   3. Try a smaller model variant\")\n",
    "    elif \"CPU\" in error_str or \"disk\" in error_str:\n",
    "        print(\"\\n🔧 System resource issue. Recommendations:\")\n",
    "        print(\"   1. Reduce batch size or sequence length\")\n",
    "        print(\"   2. Use model sharding or streaming\")\n",
    "        print(\"   3. Consider cloud-based inference\")\n",
    "    else:\n",
    "        print(f\"\\n🔍 Unexpected error type: {type(e).__name__}\")\n",
    "    \n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n💡 Summary and Next Steps:\")\n",
    "print(\"   • If SUCCESS: Run the comprehensive test (cell 9)\")\n",
    "print(\"   • If memory issues persist: Consider restarting runtime\")\n",
    "print(\"   • Alternative: Use the OpenAI API instead of local MedGemma\")\n",
    "print(\"   • For production: Use cloud instances with more GPU memory\")\n",
    "\n",
    "print(\"\\n🔧 Advanced Memory Management Applied:\")\n",
    "print(\"   ✅ Automatic GPU memory checking\")\n",
    "print(\"   ✅ Smart quantization activation\")\n",
    "print(\"   ✅ Graceful CPU fallback\")\n",
    "print(\"   ✅ Memory clearing and optimization\")\n",
    "print(\"   ✅ Conservative memory allocation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 OFFICIAL IMPLEMENTATION TEST - Following Google's Quick Start\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('src'))\n",
    "\n",
    "print(\"🎯 Testing improved MedGemma service following official Google implementation...\")\n",
    "\n",
    "try:\n",
    "    # Force reload the improved module\n",
    "    if 'src.services.ai.medgemma.medgemma_service' in sys.modules:\n",
    "        import importlib\n",
    "        importlib.reload(sys.modules['src.services.ai.medgemma.medgemma_service'])\n",
    "        print(\"   ✅ Module reloaded with official implementation improvements\")\n",
    "    \n",
    "    from src.services.ai.medgemma.medgemma_service import MedGemmaService\n",
    "    \n",
    "    print(\"   🚀 Creating MedGemma service with official configuration...\")\n",
    "    print(\"       Key improvements from official notebook:\")\n",
    "    print(\"       • torch_dtype=torch.bfloat16 (not float16)\")\n",
    "    print(\"       • device_map='auto' always used\")\n",
    "    print(\"       • do_sample=False for deterministic output\")\n",
    "    print(\"       • max_new_tokens instead of max_length\")\n",
    "    print(\"       • Auto-detection of model variants\")\n",
    "    print(\"       • Simplified pipeline creation\")\n",
    "    \n",
    "    # Create service with improved implementation\n",
    "    medgemma = MedGemmaService(\n",
    "        model_name=\"google/medgemma-4b-it\",\n",
    "        device=\"auto\",\n",
    "        use_quantization=False,  # Try without quantization first\n",
    "        multimodal=None  # Auto-detect from model name\n",
    "    )\n",
    "    \n",
    "    info = medgemma.get_model_info()\n",
    "    \n",
    "    print(f\"\\n📋 Official Implementation Results:\")\n",
    "    print(f\"   ✅ Service created successfully!\")\n",
    "    print(f\"   Model variant: {info.get('model_variant', 'Unknown')}\")\n",
    "    print(f\"   Text-only mode: {info.get('text_only', 'Unknown')}\")\n",
    "    print(f\"   Model loaded: {info['model_loaded']}\")\n",
    "    print(f\"   Pipeline ready: {info['pipeline_ready']}\")\n",
    "    print(f\"   Device: {info['device']}\")\n",
    "    print(f\"   Torch dtype: {info.get('torch_dtype', 'Unknown')}\")\n",
    "    \n",
    "    if info['model_loaded'] and info['pipeline_ready']:\n",
    "        print(\"\\n🎉 SUCCESS: Official implementation working!\")\n",
    "        print(\"   ✅ Follows Google's quick start notebook exactly\")\n",
    "        \n",
    "        # Test with official parameters\n",
    "        print(\"\\n🧪 Testing with official generation parameters...\")\n",
    "        async def test_official_generation():\n",
    "            try:\n",
    "                response = await medgemma.generate_medical_response(\n",
    "                    query=\"How do you differentiate bacterial from viral pneumonia?\",\n",
    "                    max_new_tokens=300  # Official parameter name\n",
    "                )\n",
    "                if response['success']:\n",
    "                    print(\"   ✅ Official generation test passed\")\n",
    "                    print(f\"   Max new tokens used: {response.get('max_new_tokens', 'Unknown')}\")\n",
    "                    print(f\"   Response: {response['response'][:100]}...\")\n",
    "                    return True\n",
    "                else:\n",
    "                    print(f\"   ⚠️  Generation failed: {response.get('error')}\")\n",
    "                    return False\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Generation test error: {e}\")\n",
    "                return False\n",
    "        \n",
    "        generation_success = await test_official_generation()\n",
    "        \n",
    "        if generation_success:\n",
    "            print(\"\\n🎯 COMPLETE SUCCESS: Official implementation validated!\")\n",
    "            print(\"   ✅ Model loads with official parameters\")\n",
    "            print(\"   ✅ Generation follows official format\")\n",
    "            print(\"   ✅ No more parameter mismatches\")\n",
    "        else:\n",
    "            print(\"\\n🔄 Model loaded but generation needs refinement\")\n",
    "            \n",
    "    else:\n",
    "        print(\"\\n❌ Model loading failed - check error details above\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Official implementation test failed: {e}\")\n",
    "    \n",
    "    # Provide specific guidance\n",
    "    error_str = str(e)\n",
    "    if \"CUDA out of memory\" in error_str:\n",
    "        print(\"\\n🔧 Memory issue detected:\")\n",
    "        print(\"   • The official implementation is memory-efficient\")\n",
    "        print(\"   • Try enabling quantization: use_quantization=True\")\n",
    "        print(\"   • Or restart runtime to clear GPU memory\")\n",
    "    else:\n",
    "        print(f\"   Error type: {type(e).__name__}\")\n",
    "    \n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n🎯 Key Improvements Applied:\")\n",
    "print(\"   ✅ Official torch.bfloat16 dtype (not float16)\")\n",
    "print(\"   ✅ Consistent device_map='auto' usage\")\n",
    "print(\"   ✅ Deterministic generation (do_sample=False)\")\n",
    "print(\"   ✅ max_new_tokens parameter (official)\")\n",
    "print(\"   ✅ Auto-detection of model variants\")\n",
    "print(\"   ✅ Simplified and robust pipeline creation\")\n",
    "print(\"   ✅ Memory requirement validation\")\n",
    "print(\"   ✅ Proper BitsAndBytesConfig setup\")\n",
    "\n",
    "print(\"\\n📚 Comparison with Official Notebook:\")\n",
    "print(\"   • Model loading: Now matches official implementation exactly\")\n",
    "print(\"   • Generation params: Uses official max_new_tokens and do_sample=False\")\n",
    "print(\"   • Pipeline creation: Simplified following official approach\")\n",
    "print(\"   • Error handling: Improved with official best practices\")\n",
    "print(\"   • Memory management: Better validation and configuration\")\n",
    "\n",
    "print(\"\\n💡 Next Steps:\")\n",
    "print(\"   • If SUCCESS: Your service now follows Google's official implementation\")\n",
    "print(\"   • Ready for production use with official parameters\")\n",
    "print(\"   • Compatible with all official MedGemma examples\")\n",
    "print(\"   • Optimized for stability and performance\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00391affbde34e77b271d18083501b74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "07dcea4035e0479b9edee2a4fae0fb16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a77e92e23c746ed8f6db8621824200d",
       "IPY_MODEL_e118f7b2341044d7b4e7f01175d82b51",
       "IPY_MODEL_a76177201a3d4800a0dba3eb96002f95"
      ],
      "layout": "IPY_MODEL_1b693c90a6414846ac32d755a7d5340a"
     }
    },
    "0e6383b3f3c447648468f07db8eb24d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3167dd5732f3423589786d7271b9c377",
      "placeholder": "​",
      "style": "IPY_MODEL_5c999fd4f59f49658a503efe0406d9df",
      "value": " 2.47k/2.47k [00:00&lt;00:00, 156kB/s]"
     }
    },
    "0f8424217114479e87bf3ca2772723d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f8944cc2024492a8061bcd362be4aa7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10e37d7e0ae94dcca6ee2bb40560ed68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11a97f9e988a44269831f57dbab9f442": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10e37d7e0ae94dcca6ee2bb40560ed68",
      "placeholder": "​",
      "style": "IPY_MODEL_2d940ec0e9d14397b1e27f98c7796bb2",
      "value": " 35.0/35.0 [00:00&lt;00:00, 1.78kB/s]"
     }
    },
    "11d4245dd39348b0af8f0312e0c062d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0e5a3a4e3fc4b8ba5283d41e99b1666",
      "placeholder": "​",
      "style": "IPY_MODEL_6e809e7c3d1f4cf3a3abc86839d6ed91",
      "value": "chat_template.jinja: 100%"
     }
    },
    "1a77e92e23c746ed8f6db8621824200d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f8944cc2024492a8061bcd362be4aa7",
      "placeholder": "​",
      "style": "IPY_MODEL_00391affbde34e77b271d18083501b74",
      "value": "tokenizer.json: 100%"
     }
    },
    "1b693c90a6414846ac32d755a7d5340a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d940ec0e9d14397b1e27f98c7796bb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f12aa6400f748179cdd30ef96e726a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fd41b3d39df4dd6ac179df4e18f0ae5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3844d79d609f424a931dad8b14f4f9ed",
      "placeholder": "​",
      "style": "IPY_MODEL_947fa1aab68a411392614ee099736959",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "3167dd5732f3423589786d7271b9c377": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31bf3a6d57cc4408a338e3d1c3095de2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33e758cc8bcf439885ae86f62f5de357": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3575dffbfbe6486481ae08493960753d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3844d79d609f424a931dad8b14f4f9ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f75b78b59354e568af4467f14c50710": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_843b68ec67ed40e58afebbd7ab7de8b0",
      "placeholder": "​",
      "style": "IPY_MODEL_732a556259504be1a4c4ed147c2cc7ad",
      "value": "added_tokens.json: 100%"
     }
    },
    "44ebaf24a5d54f98beaba6a6e441fb3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47c9336a07464832a37807829662c086": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31bf3a6d57cc4408a338e3d1c3095de2",
      "max": 4689074,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e10753f9bc23493a9e88c4fb27855ca4",
      "value": 4689074
     }
    },
    "4e9971d949a84b8c99f41457024ad918": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54080ad0350e4ac29a2dbe03c04ef495": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54cd0699acc84d2fbe309c231d37f60b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "56d7b72c6ec44e5ba0e14ff0b28d7cdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_86b4b1600c304a0caa7ca9766ece1a62",
       "IPY_MODEL_7977c17ffb234b1c9aea2956825311a4",
       "IPY_MODEL_66b3edc28448455387fbe5ed4105d51e"
      ],
      "layout": "IPY_MODEL_deafe0a536ff48a8bf78599bc95beb6a"
     }
    },
    "59e981e24e2d45fc9dc21beac1f58ddb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bedbc15d66841369ccfda4cba49f78d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c999fd4f59f49658a503efe0406d9df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f5c4d2c5c8f48509e85ec4f7fbe34ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6030a9fa7d5f417b9dfe239abd1810fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "617f4478b81c44e2b9b2b77eaa2d0332": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0edba34a6c74562bc0e1aeebca7de42",
      "max": 1532,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a8aad3c543d54bb199687d43c9e73148",
      "value": 1532
     }
    },
    "62a739a36a8246fa9bcd3cf788027d49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66b3edc28448455387fbe5ed4105d51e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54080ad0350e4ac29a2dbe03c04ef495",
      "placeholder": "​",
      "style": "IPY_MODEL_5bedbc15d66841369ccfda4cba49f78d",
      "value": " 662/662 [00:00&lt;00:00, 69.3kB/s]"
     }
    },
    "67a7e8c015f84d0892ee4fe374d903a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2fd41b3d39df4dd6ac179df4e18f0ae5",
       "IPY_MODEL_a1988c2aee7244da9bfc4a5bc29bf630",
       "IPY_MODEL_f2da64126c6142119450acc3e69c5a0c"
      ],
      "layout": "IPY_MODEL_6030a9fa7d5f417b9dfe239abd1810fe"
     }
    },
    "691b25932cbc43e9b83adc878ad6ba7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e809e7c3d1f4cf3a3abc86839d6ed91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "732a556259504be1a4c4ed147c2cc7ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7977c17ffb234b1c9aea2956825311a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62a739a36a8246fa9bcd3cf788027d49",
      "max": 662,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a147c15d374d499091bdf320673c6493",
      "value": 662
     }
    },
    "81e6431d1ada48b9b6844697b6469102": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94f73066781345878ae95109384a3278",
      "placeholder": "​",
      "style": "IPY_MODEL_deae0f2d9cea4331b4b61863803165d1",
      "value": "config.json: 100%"
     }
    },
    "843b68ec67ed40e58afebbd7ab7de8b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86b4b1600c304a0caa7ca9766ece1a62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c030d490a65646e3a4da1095a4e13799",
      "placeholder": "​",
      "style": "IPY_MODEL_0f8424217114479e87bf3ca2772723d6",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "872ae8b286bf401f93cc17342a31ecef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c81336fe9b484efb90f8ea29cfda1e26",
      "max": 35,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a009d15245b54eee9228f3f300a21489",
      "value": 35
     }
    },
    "88141b1dba5044aa90e07a3129045d83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91b6a91a180649bf98378c89aa35518f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f750aa16efea45d0946f7587374a7e5a",
      "placeholder": "​",
      "style": "IPY_MODEL_4e9971d949a84b8c99f41457024ad918",
      "value": " 1.53k/1.53k [00:00&lt;00:00, 145kB/s]"
     }
    },
    "947fa1aab68a411392614ee099736959": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "94f73066781345878ae95109384a3278": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9bfcdef80b754b21bc36677708c076db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33e758cc8bcf439885ae86f62f5de357",
      "placeholder": "​",
      "style": "IPY_MODEL_691b25932cbc43e9b83adc878ad6ba7d",
      "value": " 4.69M/4.69M [00:00&lt;00:00, 358kB/s]"
     }
    },
    "9e116816749446a2b78fa459de2dfbe8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a009d15245b54eee9228f3f300a21489": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a0edba34a6c74562bc0e1aeebca7de42": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a147c15d374d499091bdf320673c6493": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a1988c2aee7244da9bfc4a5bc29bf630": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab2db972ef9e48e08e07df697faba863",
      "max": 1157001,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e116816749446a2b78fa459de2dfbe8",
      "value": 1157001
     }
    },
    "a4a2e3fdc0ab4aadbe795aab8fe65c66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e34a801175e649ad95fc5f194d94a42d",
       "IPY_MODEL_47c9336a07464832a37807829662c086",
       "IPY_MODEL_9bfcdef80b754b21bc36677708c076db"
      ],
      "layout": "IPY_MODEL_f4250548431f43b98bd3e3fa5b5e8e05"
     }
    },
    "a54586aaaab64d5695c60c7a6a2ecbfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6436497902a4aeeadd9bc949376fc8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a76177201a3d4800a0dba3eb96002f95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44ebaf24a5d54f98beaba6a6e441fb3f",
      "placeholder": "​",
      "style": "IPY_MODEL_3575dffbfbe6486481ae08493960753d",
      "value": " 33.4M/33.4M [00:00&lt;00:00, 99.8MB/s]"
     }
    },
    "a8aad3c543d54bb199687d43c9e73148": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ab2db972ef9e48e08e07df697faba863": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c030d490a65646e3a4da1095a4e13799": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0e5a3a4e3fc4b8ba5283d41e99b1666": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c81336fe9b484efb90f8ea29cfda1e26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da04e707fcd3452a8d58e0ec6c7aa030": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3f75b78b59354e568af4467f14c50710",
       "IPY_MODEL_872ae8b286bf401f93cc17342a31ecef",
       "IPY_MODEL_11a97f9e988a44269831f57dbab9f442"
      ],
      "layout": "IPY_MODEL_ee5b5b77a0154d9e87e34674a9646793"
     }
    },
    "dbd392591a824224922db53c4ab7095f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "deae0f2d9cea4331b4b61863803165d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "deafe0a536ff48a8bf78599bc95beb6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0d5088b178c4e11988c19fa518d5fe4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88141b1dba5044aa90e07a3129045d83",
      "max": 2469,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ebed299f44454f99ba9bde78ac8512d4",
      "value": 2469
     }
    },
    "e10753f9bc23493a9e88c4fb27855ca4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e118f7b2341044d7b4e7f01175d82b51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59e981e24e2d45fc9dc21beac1f58ddb",
      "max": 33384570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_54cd0699acc84d2fbe309c231d37f60b",
      "value": 33384570
     }
    },
    "e34a801175e649ad95fc5f194d94a42d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6436497902a4aeeadd9bc949376fc8c",
      "placeholder": "​",
      "style": "IPY_MODEL_a54586aaaab64d5695c60c7a6a2ecbfc",
      "value": "tokenizer.model: 100%"
     }
    },
    "e6fffca3ae904a40bfe94e0da68b1cff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_11d4245dd39348b0af8f0312e0c062d4",
       "IPY_MODEL_617f4478b81c44e2b9b2b77eaa2d0332",
       "IPY_MODEL_91b6a91a180649bf98378c89aa35518f"
      ],
      "layout": "IPY_MODEL_2f12aa6400f748179cdd30ef96e726a5"
     }
    },
    "ebed299f44454f99ba9bde78ac8512d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ee5b5b77a0154d9e87e34674a9646793": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2da64126c6142119450acc3e69c5a0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbd392591a824224922db53c4ab7095f",
      "placeholder": "​",
      "style": "IPY_MODEL_5f5c4d2c5c8f48509e85ec4f7fbe34ee",
      "value": " 1.16M/1.16M [00:00&lt;00:00, 6.87MB/s]"
     }
    },
    "f4250548431f43b98bd3e3fa5b5e8e05": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4f8664326e34fa4814df4b38d9a5e38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f750aa16efea45d0946f7587374a7e5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f82e25a25d5a436bb234bf02c0140731": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_81e6431d1ada48b9b6844697b6469102",
       "IPY_MODEL_e0d5088b178c4e11988c19fa518d5fe4",
       "IPY_MODEL_0e6383b3f3c447648468f07db8eb24d7"
      ],
      "layout": "IPY_MODEL_f4f8664326e34fa4814df4b38d9a5e38"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
